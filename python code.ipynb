{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T13:13:55.378106Z","iopub.status.busy":"2023-02-21T13:13:55.377775Z","iopub.status.idle":"2023-02-21T13:14:05.173445Z","shell.execute_reply":"2023-02-21T13:14:05.172414Z","shell.execute_reply.started":"2023-02-21T13:13:55.378036Z"},"trusted":true},"outputs":[],"source":["import librosa\n","import datetime\n","import numpy as np \n","import pandas as pd \n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import IPython.display as ipd\n","import librosa.display\n","import scipy\n","import glob\n","import math\n","import warnings\n","import pickle\n","from sklearn.utils import shuffle\n","import zipfile\n","# Load the TensorBoard notebook extension.\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T13:14:05.177987Z","iopub.status.busy":"2023-02-21T13:14:05.177406Z","iopub.status.idle":"2023-02-21T13:22:10.707480Z","shell.execute_reply":"2023-02-21T13:22:10.706411Z","shell.execute_reply.started":"2023-02-21T13:14:05.177953Z"},"trusted":true},"outputs":[],"source":["for dirname, _, filenames in os.walk('/kaggle/input'):\n","    print(dirname)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T13:22:22.616553Z","iopub.status.busy":"2023-02-21T13:22:22.616229Z","iopub.status.idle":"2023-02-21T13:22:22.686863Z","shell.execute_reply":"2023-02-21T13:22:22.685631Z","shell.execute_reply.started":"2023-02-21T13:22:22.616520Z"},"trusted":true},"outputs":[],"source":["#utils.py\n","import sounddevice as sd\n","\n","def inverse_stft_transform(stft_features, window_length, overlap):\n","    return librosa.istft(stft_features, win_length=window_length, hop_length=overlap)\n","\n","\n","def revert_features_to_audio(features, phase, window_length, overlap, cleanMean=None, cleanStd=None):\n","    # scale the outpus back to the original range\n","    if cleanMean and cleanStd:\n","        features = cleanStd * features + cleanMean\n","\n","    phase = np.transpose(phase, (1, 0))\n","    features = np.squeeze(features)\n","    features = features * np.exp(1j * phase)  # that fixes the abs() ope previously done\n","\n","    features = np.transpose(features, (1, 0))\n","    return inverse_stft_transform(features, window_length=window_length, overlap=overlap)\n","\n","\n","def play(audio, sample_rate):\n","    # ipd.display(ipd.Audio(data=audio, rate=sample_rate))  # load a local WAV file\n","    sd.play(audio, sample_rate, blocking=True)\n","\n","\n","def add_noise_to_clean_audio(clean_audio, noise_signal):\n","    if len(clean_audio) >= len(noise_signal):\n","        # print(\"The noisy signal is smaller than the clean audio input. Duplicating the noise.\")\n","        while len(clean_audio) >= len(noise_signal):\n","            noise_signal = np.append(noise_signal, noise_signal)\n","\n","    ## Extract a noise segment from a random location in the noise file\n","    ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n","\n","    noiseSegment = noise_signal[ind: ind + clean_audio.size]\n","\n","    speech_power = np.sum(clean_audio ** 2)\n","    noise_power = np.sum(noiseSegment ** 2)\n","    noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n","    return noisyAudio\n","\n","def read_audio(filepath, sample_rate, normalize=True):\n","    audio, sr = librosa.load(filepath, sr=sample_rate)\n","    if normalize is True:\n","        div_fac = 1 / np.max(np.abs(audio)) / 3.0\n","        audio = audio * div_fac\n","        # audio = librosa.util.normalize(audio)\n","    return audio, sr\n","\n","\n","def prepare_input_features(stft_features, numSegments, numFeatures):\n","    noisySTFT = np.concatenate([stft_features[:, 0:numSegments - 1], stft_features], axis=1)\n","    stftSegments = np.zeros((numFeatures, numSegments, noisySTFT.shape[1] - numSegments + 1))\n","\n","    for index in range(noisySTFT.shape[1] - numSegments + 1):\n","        stftSegments[:, :, index] = noisySTFT[:, index:index + numSegments]\n","    return stftSegments\n","\n","\n","def get_input_features(predictorsList):\n","    predictors = []\n","    for noisy_stft_mag_features in predictorsList:\n","        # For CNN, the input feature consisted of 8 consecutive noisy\n","        # STFT magnitude vectors of size: 129 Ã— 8,\n","        # TODO: duration: 100ms\n","        inputFeatures = prepare_input_features(noisy_stft_mag_features)\n","        # print(\"inputFeatures.shape\", inputFeatures.shape)\n","        predictors.append(inputFeatures)\n","\n","    return predictors\n","\n","\n","def _bytes_feature(value):\n","    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","    if isinstance(value, type(tf.constant(0))):\n","        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","\n","def _float_feature(value):\n","    \"\"\"Returns a float_list from a float / double.\"\"\"\n","    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","\n","def _int64_feature(value):\n","    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n","\n","\n","def get_tf_feature(noise_stft_mag_features, clean_stft_magnitude, noise_stft_phase):\n","    noise_stft_mag_features = noise_stft_mag_features.astype(np.float32).tostring()\n","    clean_stft_magnitude = clean_stft_magnitude.astype(np.float32).tostring()\n","    noise_stft_phase = noise_stft_phase.astype(np.float32).tostring()\n","\n","    example = tf.train.Example(features=tf.train.Features(feature={\n","        'noise_stft_phase': _bytes_feature(noise_stft_phase),\n","        'noise_stft_mag_features': _bytes_feature(noise_stft_mag_features),\n","        'clean_stft_magnitude': _bytes_feature(clean_stft_magnitude)}))\n","    return example"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T13:22:22.689977Z","iopub.status.busy":"2023-02-21T13:22:22.689243Z","iopub.status.idle":"2023-02-21T13:22:22.717350Z","shell.execute_reply":"2023-02-21T13:22:22.716473Z","shell.execute_reply.started":"2023-02-21T13:22:22.689929Z"},"trusted":true},"outputs":[],"source":["#dataset.py\n","#from data_processing.feature_extractor import FeatureExtractor\n","#from utils import prepare_input_features\n","import multiprocessing\n","#from utils import get_tf_feature, read_audio\n","from sklearn.preprocessing import StandardScaler\n","\n","np.random.seed(999)\n","tf.random.set_seed(999)\n","\n","class Dataset:\n","    def __init__(self, clean_filenames, noise_filenames, **config):\n","        self.clean_filenames = clean_filenames\n","        self.noise_filenames = noise_filenames\n","        self.sample_rate = config['fs']\n","        self.overlap = config['overlap']\n","        self.window_length = config['windowLength']\n","        self.audio_max_duration = config['audio_max_duration']\n","\n","    def _sample_noise_filename(self):\n","        return np.random.choice(self.noise_filenames)\n","\n","    def _remove_silent_frames(self, audio):\n","        trimed_audio = []\n","        indices = librosa.effects.split(audio, hop_length=self.overlap, top_db=20)\n","\n","        for index in indices:\n","            trimed_audio.extend(audio[index[0]: index[1]])\n","        return np.array(trimed_audio)\n","\n","    def _phase_aware_scaling(self, clean_spectral_magnitude, clean_phase, noise_phase):\n","        assert clean_phase.shape == noise_phase.shape, \"Shapes must match.\"\n","        return clean_spectral_magnitude * np.cos(clean_phase - noise_phase)\n","\n","    def get_noisy_audio(self, *, filename):\n","        return read_audio(filename, self.sample_rate)\n","\n","    def _audio_random_crop(self, audio, duration):\n","        audio_duration_secs = librosa.core.get_duration(audio, self.sample_rate)\n","\n","        ## duration: length of the cropped audio in seconds\n","        if duration >= audio_duration_secs:\n","            # print(\"Passed duration greater than audio duration of: \", audio_duration_secs)\n","            return audio\n","\n","        audio_duration_ms = math.floor(audio_duration_secs * self.sample_rate)\n","        duration_ms = math.floor(duration * self.sample_rate)\n","        idx = np.random.randint(0, audio_duration_ms - duration_ms)\n","        return audio[idx: idx + duration_ms]\n","\n","    def _add_noise_to_clean_audio(self, clean_audio, noise_signal):\n","        if len(clean_audio) >= len(noise_signal):\n","            # print(\"The noisy signal is smaller than the clean audio input. Duplicating the noise.\")\n","            while len(clean_audio) >= len(noise_signal):\n","                noise_signal = np.append(noise_signal, noise_signal)\n","\n","        ## Extract a noise segment from a random location in the noise file\n","        ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n","\n","        noiseSegment = noise_signal[ind: ind + clean_audio.size]\n","\n","        speech_power = np.sum(clean_audio ** 2)\n","        noise_power = np.sum(noiseSegment ** 2)\n","        noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n","        return noisyAudio\n","\n","    def parallel_audio_processing(self, clean_filename):\n","\n","        clean_audio, _ = read_audio(clean_filename, self.sample_rate)\n","\n","        # remove silent frame from clean audio\n","        clean_audio = self._remove_silent_frames(clean_audio)\n","\n","        noise_filename = self._sample_noise_filename()\n","\n","        # read the noise filename\n","        noise_audio, sr = read_audio(noise_filename, self.sample_rate)\n","\n","        # remove silent frame from noise audio\n","        noise_audio = self._remove_silent_frames(noise_audio)\n","\n","        # sample random fixed-sized snippets of audio\n","        clean_audio = self._audio_random_crop(clean_audio, duration=self.audio_max_duration)\n","\n","        # add noise to input image\n","        noiseInput = self._add_noise_to_clean_audio(clean_audio, noise_audio)\n","\n","        # extract stft features from noisy audio\n","        noisy_input_fe = FeatureExtractor(noiseInput, windowLength=self.window_length, overlap=self.overlap,\n","                                          sample_rate=self.sample_rate)\n","        noise_spectrogram = noisy_input_fe.get_stft_spectrogram()\n","\n","        # Or get the phase angle (in radians)\n","        # noisy_stft_magnitude, noisy_stft_phase = librosa.magphase(noisy_stft_features)\n","        noise_phase = np.angle(noise_spectrogram)\n","\n","        # get the magnitude of the spectral\n","        noise_magnitude = np.abs(noise_spectrogram)\n","\n","        # extract stft features from clean audio\n","        clean_audio_fe = FeatureExtractor(clean_audio, windowLength=self.window_length, overlap=self.overlap,\n","                                          sample_rate=self.sample_rate)\n","        clean_spectrogram = clean_audio_fe.get_stft_spectrogram()\n","        # clean_spectrogram = cleanAudioFE.get_mel_spectrogram()\n","\n","        # get the clean phase\n","        clean_phase = np.angle(clean_spectrogram)\n","\n","        # get the clean spectral magnitude\n","        clean_magnitude = np.abs(clean_spectrogram)\n","        # clean_magnitude = 2 * clean_magnitude / np.sum(scipy.signal.hamming(self.window_length, sym=False))\n","\n","        clean_magnitude = self._phase_aware_scaling(clean_magnitude, clean_phase, noise_phase)\n","\n","        scaler = StandardScaler(copy=False, with_mean=True, with_std=True)\n","        noise_magnitude = scaler.fit_transform(noise_magnitude)\n","        clean_magnitude = scaler.transform(clean_magnitude)\n","\n","        return noise_magnitude, clean_magnitude, noise_phase\n","\n","    def create_tf_record(self, *, prefix, subset_size, parallel=True):\n","        counter = 0\n","        p = multiprocessing.Pool(multiprocessing.cpu_count())\n","\n","        for i in range(0, len(self.clean_filenames), subset_size):\n","\n","            tfrecord_filename =prefix + '_' + str(counter) + '.tfrecords'\n","\n","            if os.path.isfile(tfrecord_filename):\n","                print(f\"Skipping {tfrecord_filename}\")\n","                counter += 1\n","                continue\n","\n","            writer = tf.io.TFRecordWriter(tfrecord_filename)\n","            clean_filenames_sublist = self.clean_filenames[i:i + subset_size]\n","\n","            print(f\"Processing files from: {i} to {i + subset_size}\")\n","            \n","            if parallel:\n","                out = p.map(self.parallel_audio_processing, clean_filenames_sublist)\n","            else:\n","                out = [self.parallel_audio_processing(filename) for filename in clean_filenames_sublist]\n","\n","            for o in out:\n","                noise_stft_magnitude = o[0]\n","                clean_stft_magnitude = o[1]\n","                noise_stft_phase = o[2]\n","\n","                noise_stft_mag_features = prepare_input_features(noise_stft_magnitude, numSegments=8, numFeatures=129)\n","\n","                noise_stft_mag_features = np.transpose(noise_stft_mag_features, (2, 0, 1))\n","                clean_stft_magnitude = np.transpose(clean_stft_magnitude, (1, 0))\n","                noise_stft_phase = np.transpose(noise_stft_phase, (1, 0))\n","\n","                noise_stft_mag_features = np.expand_dims(noise_stft_mag_features, axis=3)\n","                clean_stft_magnitude = np.expand_dims(clean_stft_magnitude, axis=2)\n","\n","                for x_, y_, p_ in zip(noise_stft_mag_features, clean_stft_magnitude, noise_stft_phase):\n","                    y_ = np.expand_dims(y_, 2)\n","                    example = get_tf_feature(x_, y_, p_)\n","                    writer.write(example.SerializeToString())\n","\n","            counter += 1\n","            writer.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T13:22:22.719306Z","iopub.status.busy":"2023-02-21T13:22:22.718945Z","iopub.status.idle":"2023-02-21T13:22:22.731971Z","shell.execute_reply":"2023-02-21T13:22:22.731066Z","shell.execute_reply.started":"2023-02-21T13:22:22.719235Z"},"trusted":true},"outputs":[],"source":["#feature_extractor.py\n","import scipy\n","\n","class FeatureExtractor:\n","    def __init__(self, audio, *, windowLength, overlap, sample_rate):\n","        self.audio = audio\n","        self.ffT_length = windowLength\n","        self.window_length = windowLength\n","        self.overlap = overlap\n","        self.sample_rate = sample_rate\n","        self.window = scipy.signal.hamming(self.window_length, sym=False)\n","\n","    def get_stft_spectrogram(self):\n","        return librosa.stft(self.audio, n_fft=self.ffT_length, win_length=self.window_length, hop_length=self.overlap,\n","                            window=self.window, center=True)\n","\n","    def get_audio_from_stft_spectrogram(self, stft_features):\n","        return librosa.istft(stft_features, win_length=self.window_length, hop_length=self.overlap,\n","                             window=self.window, center=True)\n","\n","    def get_mel_spectrogram(self):\n","        return librosa.feature.melspectrogram(self.audio, sr=self.sample_rate, power=2.0, pad_mode='reflect',\n","                                              n_fft=self.ffT_length, hop_length=self.overlap, center=True)\n","\n","    def get_audio_from_mel_spectrogram(self, M):\n","        return librosa.feature.inverse.mel_to_audio(M, sr=self.sample_rate, n_fft=self.ffT_length,\n","                                                    hop_length=self.overlap,\n","                                                    win_length=self.window_length, window=self.window,\n","                                                    center=True, pad_mode='reflect', power=2.0, n_iter=32, length=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T13:22:22.733723Z","iopub.status.busy":"2023-02-21T13:22:22.733312Z","iopub.status.idle":"2023-02-21T13:22:22.746042Z","shell.execute_reply":"2023-02-21T13:22:22.745028Z","shell.execute_reply.started":"2023-02-21T13:22:22.733687Z"},"trusted":true},"outputs":[],"source":["#commonvoice.py\n","np.random.seed(999)\n","\n","class MozillaCommonVoiceDataset:\n","\n","    def __init__(self, basepath, *, val_dataset_size):\n","        self.basepath = basepath\n","        self.val_dataset_size = val_dataset_size\n","\n","    def _get_common_voice_filenames(self, dataframe_name='cv-valid-train.csv'):\n","        mozilla_metadata = pd.read_csv(os.path.join(self.basepath, dataframe_name))\n","        clean_files = mozilla_metadata['filename'].values\n","        np.random.shuffle(clean_files)\n","        print(\"Total number of training examples:\", len(clean_files))\n","        return clean_files\n","\n","    def get_train_val_filenames(self):\n","        clean_files = self._get_common_voice_filenames(dataframe_name='cv-valid-train.csv')\n","\n","        # resolve full path\n","        clean_files = [os.path.join(self.basepath,'cv-valid-train', filename) for filename in clean_files]\n","\n","        clean_files = clean_files[:-self.val_dataset_size]\n","        clean_val_files = clean_files[-self.val_dataset_size:]\n","        print(\"# of Training clean files:\", len(clean_files))\n","        print(\"# of  Validation clean files:\", len(clean_val_files))\n","        return clean_files, clean_val_files\n","\n","\n","    def get_test_filenames(self):\n","        clean_files = self._get_common_voice_filenames(dataframe_name='cv-valid-test.csv')\n","\n","        # resolve full path\n","        clean_files = [os.path.join(self.basepath,'cv-valid-test', filename) for filename in clean_files]\n","\n","        print(\"# of Testing clean files:\", len(clean_files))\n","        return clean_files"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T13:22:22.748020Z","iopub.status.busy":"2023-02-21T13:22:22.747437Z","iopub.status.idle":"2023-02-21T13:22:22.762374Z","shell.execute_reply":"2023-02-21T13:22:22.761309Z","shell.execute_reply.started":"2023-02-21T13:22:22.747982Z"},"trusted":true},"outputs":[],"source":["#urbansound8k.py\n","np.random.seed(999)\n","\n","class UrbanSound8K:\n","    def __init__(self, basepath, *, val_dataset_size, class_ids=None):\n","        self.basepath = basepath\n","        self.val_dataset_size = val_dataset_size\n","        self.class_ids = class_ids\n","\n","    def _get_urban_sound_8K_filenames(self):\n","        urbansound_metadata = pd.read_csv(os.path.join(self.basepath, 'UrbanSound8K.csv'))\n","\n","        # shuffle the dataframe\n","        urbansound_metadata.reindex(np.random.permutation(urbansound_metadata.index))\n","\n","        return urbansound_metadata\n","\n","    def _get_filenames_by_class_id(self, metadata):\n","\n","        if self.class_ids is None:\n","            self.class_ids = np.unique(metadata['classID'].values)\n","            print(\"Number of classes:\", self.class_ids)\n","\n","        all_files = []\n","        file_counter = 0\n","        for c in self.class_ids:\n","            per_class_files = metadata[metadata['classID'] == c][['slice_file_name', 'fold']].values\n","            per_class_files = [os.path.join(self.basepath,'fold' + str(file[1]), file[0]) for file in\n","                               per_class_files]\n","            print(\"Class c:\", str(c), 'has:', len(per_class_files), 'files')\n","            file_counter += len(per_class_files)\n","            all_files.extend(per_class_files)\n","\n","        assert len(all_files) == file_counter\n","        return all_files\n","\n","    def get_train_val_filenames(self):\n","        urbansound_metadata = self._get_urban_sound_8K_filenames()\n","\n","        # folds from 0 to 9 are used for training\n","        urbansound_train = urbansound_metadata[urbansound_metadata.fold != 10]\n","\n","        urbansound_train_filenames = self._get_filenames_by_class_id(urbansound_train)\n","        np.random.shuffle(urbansound_train_filenames)\n","\n","        # separate noise files for train/validation\n","        urbansound_val = urbansound_train_filenames[-self.val_dataset_size:]\n","        urbansound_train = urbansound_train_filenames[:-self.val_dataset_size]\n","        print(\"Noise training:\", len(urbansound_train))\n","        print(\"Noise validation:\", len(urbansound_val))\n","\n","        return urbansound_train, urbansound_val\n","\n","    def get_test_filenames(self):\n","        urbansound_metadata = self._get_urban_sound_8K_filenames()\n","\n","        # fold 10 is used for testing only\n","        urbansound_train = urbansound_metadata[urbansound_metadata.fold == 10]\n","\n","        urbansound_test_filenames = self._get_filenames_by_class_id(urbansound_train)\n","        np.random.shuffle(urbansound_test_filenames)\n","\n","        print(\"# of Noise testing files:\", len(urbansound_test_filenames))\n","        return urbansound_test_filenames"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T13:25:39.248684Z","iopub.status.busy":"2023-02-21T13:25:39.248316Z","iopub.status.idle":"2023-02-21T13:31:11.331529Z","shell.execute_reply":"2023-02-21T13:31:11.330248Z","shell.execute_reply.started":"2023-02-21T13:25:39.248651Z"},"trusted":true},"outputs":[],"source":["#create_datset.py\n","#from data_processing.mozilla_common_voice import MozillaCommonVoiceDataset\n","#from data_processing.urban_sound_8K import UrbanSound8K\n","#from data_processing.dataset import Dataset\n","import warnings\n","\n","warnings.filterwarnings(action='ignore')\n","\n","mozilla_basepath = '/kaggle/input/common-voice'\n","urbansound_basepath = '/kaggle/input/urbansound8k'\n","\n","mcv = MozillaCommonVoiceDataset(mozilla_basepath, val_dataset_size=1000)\n","clean_train_filenames, clean_val_filenames = mcv.get_train_val_filenames()\n","\n","us8K = UrbanSound8K(urbansound_basepath, val_dataset_size=200)\n","noise_train_filenames, noise_val_filenames = us8K.get_train_val_filenames()\n","\n","windowLength = 256\n","config = {'windowLength': windowLength,\n","          'overlap': round(0.25 * windowLength),\n","          'fs': 16000,\n","          'audio_max_duration': 0.8}\n","\n","val_dataset = Dataset(clean_val_filenames, noise_val_filenames, **config)\n","val_dataset.create_tf_record(prefix='val', subset_size=1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T13:31:11.334990Z","iopub.status.busy":"2023-02-21T13:31:11.334539Z","iopub.status.idle":"2023-02-21T14:01:40.996710Z","shell.execute_reply":"2023-02-21T14:01:40.993092Z","shell.execute_reply.started":"2023-02-21T13:31:11.334938Z"},"trusted":true},"outputs":[],"source":["#Train data\n","train_dataset = Dataset(clean_train_filenames, noise_train_filenames, **config)\n","train_dataset.create_tf_record(prefix='train', subset_size=4000)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:28:55.116311Z","iopub.status.busy":"2023-02-21T14:28:55.115897Z","iopub.status.idle":"2023-02-21T14:37:07.315733Z","shell.execute_reply":"2023-02-21T14:37:07.313915Z","shell.execute_reply.started":"2023-02-21T14:28:55.116278Z"},"trusted":true},"outputs":[],"source":["## Create Test Set\n","clean_test_filenames = mcv.get_test_filenames()\n","noise_test_filenames = us8K.get_test_filenames()\n","\n","test_dataset = Dataset(clean_test_filenames, noise_test_filenames, **config)\n","test_dataset.create_tf_record(prefix='test', subset_size=500, parallel=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:28:51.118399Z","iopub.status.busy":"2023-02-21T14:28:51.118018Z","iopub.status.idle":"2023-02-21T14:28:51.497574Z","shell.execute_reply":"2023-02-21T14:28:51.496421Z","shell.execute_reply.started":"2023-02-21T14:28:51.118366Z"},"trusted":true},"outputs":[],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:40:17.307024Z","iopub.status.busy":"2023-02-21T14:40:17.306607Z","iopub.status.idle":"2023-02-21T14:40:17.339877Z","shell.execute_reply":"2023-02-21T14:40:17.338816Z","shell.execute_reply.started":"2023-02-21T14:40:17.306990Z"},"id":"VoyZ5yLRaAeI","trusted":true},"outputs":[],"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:40:19.183861Z","iopub.status.busy":"2023-02-21T14:40:19.183170Z","iopub.status.idle":"2023-02-21T14:40:19.201893Z","shell.execute_reply":"2023-02-21T14:40:19.200719Z","shell.execute_reply.started":"2023-02-21T14:40:19.183810Z"},"id":"WBZyUMpobR-Z","trusted":true},"outputs":[],"source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:40:22.410106Z","iopub.status.busy":"2023-02-21T14:40:22.408981Z","iopub.status.idle":"2023-02-21T14:40:22.417186Z","shell.execute_reply":"2023-02-21T14:40:22.415729Z","shell.execute_reply.started":"2023-02-21T14:40:22.410062Z"},"id":"zu2lgR8lEmu0","trusted":true},"outputs":[],"source":["tf.random.set_seed(999)\n","np.random.seed(999)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-02-21T11:27:32.895694Z","iopub.status.idle":"2023-02-21T11:27:32.899728Z","shell.execute_reply":"2023-02-21T11:27:32.899456Z","shell.execute_reply.started":"2023-02-21T11:27:32.899426Z"},"id":"JGbkvQHxxrj_","trusted":true},"outputs":[],"source":["#!wget 'cdn.daitan.com/dataset.zip'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-02-21T11:27:32.902410Z","iopub.status.idle":"2023-02-21T11:27:32.903977Z","shell.execute_reply":"2023-02-21T11:27:32.903001Z","shell.execute_reply.started":"2023-02-21T11:27:32.902974Z"},"id":"51o6Ze9hxrkE","trusted":true},"outputs":[],"source":["#dataset_file_name = './dataset.zip'\n","#with zipfile.ZipFile(dataset_file_name, 'r') as zip_ref:\n","#    zip_ref.extractall('./dataset')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:40:35.875491Z","iopub.status.busy":"2023-02-21T14:40:35.875130Z","iopub.status.idle":"2023-02-21T14:40:35.880982Z","shell.execute_reply":"2023-02-21T14:40:35.879552Z","shell.execute_reply.started":"2023-02-21T14:40:35.875460Z"},"id":"d43UvhEqxrkJ","trusted":true},"outputs":[],"source":["path_to_dataset = \"/kaggle/working/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:08.057557Z","iopub.status.busy":"2023-02-21T14:41:08.057176Z","iopub.status.idle":"2023-02-21T14:41:08.065711Z","shell.execute_reply":"2023-02-21T14:41:08.064630Z","shell.execute_reply.started":"2023-02-21T14:41:08.057526Z"},"id":"W36WF4mT1kGK","trusted":true},"outputs":[],"source":["# get training and validation tf record file names\n","train_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'train_*'))\n","val_tfrecords_filenames = glob.glob(os.path.join(path_to_dataset, 'val_*'))\n","\n","# suffle the file names for training\n","np.random.shuffle(train_tfrecords_filenames)\n","print(\"Training file names: \", train_tfrecords_filenames)\n","print(\"Validation file names: \", val_tfrecords_filenames)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:14.429039Z","iopub.status.busy":"2023-02-21T14:41:14.428658Z","iopub.status.idle":"2023-02-21T14:41:14.437066Z","shell.execute_reply":"2023-02-21T14:41:14.435986Z","shell.execute_reply.started":"2023-02-21T14:41:14.429005Z"},"id":"jKZtPoLMEmvJ","trusted":true},"outputs":[],"source":["windowLength = 256\n","overlap      = round(0.25 * windowLength) # overlap of 75%\n","ffTLength    = windowLength\n","inputFs      = 48e3\n","fs           = 16e3\n","numFeatures  = ffTLength//2 + 1\n","numSegments  = 8\n","print(\"windowLength:\",windowLength)\n","print(\"overlap:\",overlap)\n","print(\"ffTLength:\",ffTLength)\n","print(\"inputFs:\",inputFs)\n","print(\"fs:\",fs)\n","print(\"numFeatures:\",numFeatures)\n","print(\"numSegments:\",numSegments)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:16.280113Z","iopub.status.busy":"2023-02-21T14:41:16.279737Z","iopub.status.idle":"2023-02-21T14:41:16.286349Z","shell.execute_reply":"2023-02-21T14:41:16.284306Z","shell.execute_reply.started":"2023-02-21T14:41:16.280082Z"},"id":"JXpSGe8L0cl_","trusted":true},"outputs":[],"source":["mozilla_basepath = '/kaggle/input/common-voice'\n","UrbanSound8K_basepath = '/kaggle/input/urbansound8k'"]},{"cell_type":"markdown","metadata":{"id":"zzbdfIi-Lgk9"},"source":["## Prepare Input features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:21.525020Z","iopub.status.busy":"2023-02-21T14:41:21.524625Z","iopub.status.idle":"2023-02-21T14:41:21.533022Z","shell.execute_reply":"2023-02-21T14:41:21.531841Z","shell.execute_reply.started":"2023-02-21T14:41:21.524984Z"},"id":"24kph3wJ3s5V","trusted":true},"outputs":[],"source":["def tf_record_parser(record):\n","    keys_to_features = {\n","        \"noise_stft_phase\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n","        'noise_stft_mag_features': tf.io.FixedLenFeature([], tf.string),\n","        \"clean_stft_magnitude\": tf.io.FixedLenFeature((), tf.string)\n","    }\n","\n","    features = tf.io.parse_single_example(record, keys_to_features)\n","\n","    noise_stft_mag_features = tf.io.decode_raw(features['noise_stft_mag_features'], tf.float32)\n","    clean_stft_magnitude = tf.io.decode_raw(features['clean_stft_magnitude'], tf.float32)\n","    noise_stft_phase = tf.io.decode_raw(features['noise_stft_phase'], tf.float32)\n","\n","    # reshape input and annotation images\n","    noise_stft_mag_features = tf.reshape(noise_stft_mag_features, (129, 8, 1), name=\"noise_stft_mag_features\")\n","    clean_stft_magnitude = tf.reshape(clean_stft_magnitude, (129, 1, 1), name=\"clean_stft_magnitude\")\n","    noise_stft_phase = tf.reshape(noise_stft_phase, (129,), name=\"noise_stft_phase\")\n","\n","    return noise_stft_mag_features, clean_stft_magnitude"]},{"cell_type":"markdown","metadata":{"id":"uJXPGrgVTCbZ"},"source":["## Create tf.Data.Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:24.103004Z","iopub.status.busy":"2023-02-21T14:41:24.101612Z","iopub.status.idle":"2023-02-21T14:41:24.554040Z","shell.execute_reply":"2023-02-21T14:41:24.553029Z","shell.execute_reply.started":"2023-02-21T14:41:24.102959Z"},"id":"FF_A3YbZTCsj","trusted":true},"outputs":[],"source":["train_dataset = tf.data.TFRecordDataset([train_tfrecords_filenames])\n","train_dataset = train_dataset.map(tf_record_parser)\n","train_dataset = train_dataset.shuffle(8192)\n","train_dataset = train_dataset.repeat()\n","train_dataset = train_dataset.batch(512)\n","train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:24.845373Z","iopub.status.busy":"2023-02-21T14:41:24.845058Z","iopub.status.idle":"2023-02-21T14:41:24.875140Z","shell.execute_reply":"2023-02-21T14:41:24.874221Z","shell.execute_reply.started":"2023-02-21T14:41:24.845344Z"},"id":"NOuWPzQaTNDy","trusted":true},"outputs":[],"source":["test_dataset = tf.data.TFRecordDataset([val_tfrecords_filenames])\n","test_dataset = test_dataset.map(tf_record_parser)\n","test_dataset = test_dataset.repeat(1)\n","test_dataset = test_dataset.batch(512)"]},{"cell_type":"markdown","metadata":{"id":"CEG5JofLSfRw"},"source":["## Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:28.087296Z","iopub.status.busy":"2023-02-21T14:41:28.086937Z","iopub.status.idle":"2023-02-21T14:41:28.098739Z","shell.execute_reply":"2023-02-21T14:41:28.097608Z","shell.execute_reply.started":"2023-02-21T14:41:28.087266Z"},"id":"2OZFegXrSYle","trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation\n","from tensorflow.keras import Model, Sequential"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:28.867061Z","iopub.status.busy":"2023-02-21T14:41:28.866417Z","iopub.status.idle":"2023-02-21T14:41:28.873611Z","shell.execute_reply":"2023-02-21T14:41:28.872317Z","shell.execute_reply.started":"2023-02-21T14:41:28.867026Z"},"id":"lc2K0cfhPU5-","trusted":true},"outputs":[],"source":["def conv_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n","  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n","  x = Activation('relu')(x)\n","  if use_bn:\n","    x = BatchNormalization()(x)\n","  return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:29.683906Z","iopub.status.busy":"2023-02-21T14:41:29.682837Z","iopub.status.idle":"2023-02-21T14:41:29.694124Z","shell.execute_reply":"2023-02-21T14:41:29.690296Z","shell.execute_reply.started":"2023-02-21T14:41:29.683833Z"},"id":"XFYyKoAVQYCz","trusted":true},"outputs":[],"source":["def full_pre_activation_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n","  shortcut = x\n","  in_channels = x.shape[-1]\n","\n","  x = BatchNormalization()(x)\n","  x = Activation('relu')(x)\n","  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n","\n","  x = BatchNormalization()(x)\n","  x = Activation('relu')(x)\n","  x = Conv2D(filters=in_channels, kernel_size=kernel_size, strides=strides, padding='same')(x)\n","\n","  return shortcut + x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:30.435671Z","iopub.status.busy":"2023-02-21T14:41:30.435323Z","iopub.status.idle":"2023-02-21T14:41:30.459589Z","shell.execute_reply":"2023-02-21T14:41:30.458431Z","shell.execute_reply.started":"2023-02-21T14:41:30.435639Z"},"id":"NlRQ3ngpZG1Y","trusted":true},"outputs":[],"source":["def build_model(l2_strength):\n","  inputs = Input(shape=[numFeatures,numSegments,1])\n","  x = inputs\n","\n","  # -----\n","  x = tf.keras.layers.ZeroPadding2D(((4,4), (0,0)))(x)\n","  x = Conv2D(filters=18, kernel_size=[9,8], strides=[1, 1], padding='valid', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  skip0 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n","                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(skip0)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  # -----\n","  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  skip1 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n","                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(skip1)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  # ----\n","  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","  \n","  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  # ----\n","  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n","             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = x + skip1\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  # ----\n","  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n","             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = x + skip0\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  # ----\n","  x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n","  x = Conv2D(filters=1, kernel_size=[129,1], strides=[1, 1], padding='same')(x)\n","\n","  model = Model(inputs=inputs, outputs=x)\n","\n","  optimizer = tf.keras.optimizers.Adam(3e-4)\n","  #optimizer = RAdam(total_steps=10000, warmup_proportion=0.1, min_lr=3e-4)\n","\n","  model.compile(optimizer=optimizer, loss='mse', \n","                metrics=[tf.keras.metrics.RootMeanSquaredError('rmse')])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:31.164567Z","iopub.status.busy":"2023-02-21T14:41:31.163904Z","iopub.status.idle":"2023-02-21T14:41:31.679114Z","shell.execute_reply":"2023-02-21T14:41:31.678336Z","shell.execute_reply.started":"2023-02-21T14:41:31.164524Z"},"id":"mNpHS4LuShxd","trusted":true},"outputs":[],"source":["model = build_model(l2_strength=0.0)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:34.378373Z","iopub.status.busy":"2023-02-21T14:41:34.377980Z","iopub.status.idle":"2023-02-21T14:41:35.142871Z","shell.execute_reply":"2023-02-21T14:41:35.141731Z","shell.execute_reply.started":"2023-02-21T14:41:34.378343Z"},"id":"8rWOgsdwglFE","trusted":true},"outputs":[],"source":["# You might need to install the following dependencies: sudo apt install python-pydot python-pydot-ng graphviz\n","tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:37.420684Z","iopub.status.busy":"2023-02-21T14:41:37.420296Z","iopub.status.idle":"2023-02-21T14:41:47.090815Z","shell.execute_reply":"2023-02-21T14:41:47.089578Z","shell.execute_reply.started":"2023-02-21T14:41:37.420646Z"},"id":"7OdmgHTp4_Ou","trusted":true},"outputs":[],"source":["%tensorboard --logdir logs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:41:47.094323Z","iopub.status.busy":"2023-02-21T14:41:47.093583Z","iopub.status.idle":"2023-02-21T14:42:08.168570Z","shell.execute_reply":"2023-02-21T14:42:08.167533Z","shell.execute_reply.started":"2023-02-21T14:41:47.094274Z"},"id":"BucSAwkHQj8Q","trusted":true},"outputs":[],"source":["baseline_val_loss = model.evaluate(test_dataset)[0]\n","print(f\"Baseline accuracy {baseline_val_loss}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:42:11.611342Z","iopub.status.busy":"2023-02-21T14:42:11.610960Z","iopub.status.idle":"2023-02-21T14:42:11.618272Z","shell.execute_reply":"2023-02-21T14:42:11.616947Z","shell.execute_reply.started":"2023-02-21T14:42:11.611311Z"},"id":"ocycFbP5-X0o","trusted":true},"outputs":[],"source":["def l2_norm(vector):\n","    return np.square(vector)\n","\n","def SDR(denoised, cleaned, eps=1e-7): # Signal to Distortion Ratio\n","    a = l2_norm(denoised)\n","    b = l2_norm(denoised - cleaned)\n","    a_b = a / b\n","    return np.mean(10 * np.log10(a_b + eps))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T14:42:48.945630Z","iopub.status.busy":"2023-02-21T14:42:48.943698Z","iopub.status.idle":"2023-02-21T16:11:04.411180Z","shell.execute_reply":"2023-02-21T16:11:04.409667Z","shell.execute_reply.started":"2023-02-21T14:42:48.945562Z"},"id":"bcPAuMZ9SlHa","trusted":true},"outputs":[],"source":["early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, baseline=None)\n","\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, update_freq='batch')\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./denoiser_cnn_log_mel_generator.h5', \n","                                                         monitor='val_loss', save_best_only=True)\n","\n","model.fit(train_dataset,\n","         steps_per_epoch=400, # you might need to change this\n","         validation_data=test_dataset,\n","         epochs=200,\n","         callbacks=[early_stopping_callback, tensorboard_callback, checkpoint_callback]\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:11:04.417914Z","iopub.status.busy":"2023-02-21T16:11:04.417557Z","iopub.status.idle":"2023-02-21T16:12:11.067305Z","shell.execute_reply":"2023-02-21T16:12:11.066263Z","shell.execute_reply.started":"2023-02-21T16:11:04.417877Z"},"id":"g1ZZskDZ5L2a","trusted":true},"outputs":[],"source":["val_loss = model.evaluate(test_dataset)[0]\n","if val_loss < baseline_val_loss:\n","  print(\"New model saved.\")\n","  model.save('./denoiser_cnn_log_mel_generator.h5')"]},{"cell_type":"markdown","metadata":{"id":"LeJTsGxCSuhm"},"source":["## Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:20:22.584373Z","iopub.status.busy":"2023-02-21T16:20:22.583987Z","iopub.status.idle":"2023-02-21T16:20:22.594884Z","shell.execute_reply":"2023-02-21T16:20:22.592865Z","shell.execute_reply.started":"2023-02-21T16:20:22.584342Z"},"id":"DLiTiK8blE0n","trusted":true},"outputs":[],"source":["def read_audio(filepath, sample_rate, normalize=True):\n","    \"\"\"Read an audio file and return it as a numpy array\"\"\"\n","    audio, sr = librosa.load(filepath, sr=sample_rate)\n","    if normalize:\n","      div_fac = 1 / np.max(np.abs(audio)) / 3.0\n","      audio = audio * div_fac\n","    return audio, sr\n","        \n","def add_noise_to_clean_audio(clean_audio, noise_signal):\n","    \"\"\"Adds noise to an audio sample\"\"\"\n","    if len(clean_audio) >= len(noise_signal):\n","        # print(\"The noisy signal is smaller than the clean audio input. Duplicating the noise.\")\n","        while len(clean_audio) >= len(noise_signal):\n","            noise_signal = np.append(noise_signal, noise_signal)\n","\n","    ## Extract a noise segment from a random location in the noise file\n","    ind = np.random.randint(0, noise_signal.size - clean_audio.size)\n","\n","    noiseSegment = noise_signal[ind: ind + clean_audio.size]\n","\n","    speech_power = np.sum(clean_audio ** 2)\n","    noise_power = np.sum(noiseSegment ** 2)\n","    noisyAudio = clean_audio + np.sqrt(speech_power / noise_power) * noiseSegment\n","    return noisyAudio\n","\n","def play(audio, sample_rate):\n","    ipd.display(ipd.Audio(data=audio, rate=sample_rate))  # load a local WAV file"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:20:23.197802Z","iopub.status.busy":"2023-02-21T16:20:23.197112Z","iopub.status.idle":"2023-02-21T16:20:23.208359Z","shell.execute_reply":"2023-02-21T16:20:23.206992Z","shell.execute_reply.started":"2023-02-21T16:20:23.197761Z"},"id":"uM6ajbBFlx3b","trusted":true},"outputs":[],"source":["class FeatureExtractor:\n","    def __init__(self, audio, *, windowLength, overlap, sample_rate):\n","        self.audio = audio\n","        self.ffT_length = windowLength\n","        self.window_length = windowLength\n","        self.overlap = overlap\n","        self.sample_rate = sample_rate\n","        self.window = scipy.signal.hamming(self.window_length, sym=False)\n","\n","    def get_stft_spectrogram(self):\n","        return librosa.stft(self.audio, n_fft=self.ffT_length, win_length=self.window_length, hop_length=self.overlap,\n","                            window=self.window, center=True)\n","\n","    def get_audio_from_stft_spectrogram(self, stft_features):\n","        return librosa.istft(stft_features, win_length=self.window_length, hop_length=self.overlap,\n","                             window=self.window, center=True)\n","\n","    def get_mel_spectrogram(self):\n","        return librosa.feature.melspectrogram(self.audio, sr=self.sample_rate, power=2.0, pad_mode='reflect',\n","                                           n_fft=self.ffT_length, hop_length=self.overlap, center=True)\n","\n","    def get_audio_from_mel_spectrogram(self, M):\n","        return librosa.feature.inverse.mel_to_audio(M, sr=self.sample_rate, n_fft=self.ffT_length, hop_length=self.overlap,\n","                                             win_length=self.window_length, window=self.window,\n","                                             center=True, pad_mode='reflect', power=2.0, n_iter=32, length=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:27:33.062753Z","iopub.status.busy":"2023-02-21T16:27:33.062375Z","iopub.status.idle":"2023-02-21T16:27:34.219422Z","shell.execute_reply":"2023-02-21T16:27:34.218293Z","shell.execute_reply.started":"2023-02-21T16:27:33.062720Z"},"id":"9dcnyvquSoLs","trusted":true},"outputs":[],"source":["cleanAudio, sr = read_audio(os.path.join(mozilla_basepath,'cv-valid-test','cv-valid-test','sample-000000.mp3'), sample_rate=fs)\n","print(\"Min:\", np.min(cleanAudio),\"Max:\",np.max(cleanAudio))\n","ipd.Audio(data=cleanAudio, rate=sr) # load a local WAV file"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:28:47.558057Z","iopub.status.busy":"2023-02-21T16:28:47.557651Z","iopub.status.idle":"2023-02-21T16:28:47.682998Z","shell.execute_reply":"2023-02-21T16:28:47.681913Z","shell.execute_reply.started":"2023-02-21T16:28:47.558022Z"},"id":"BaHe1okPTvV-","trusted":true},"outputs":[],"source":["noiseAudio, sr = read_audio(os.path.join(UrbanSound8K_basepath,'fold1/101415-3-0-2.wav'), sample_rate=fs)\n","print(\"Min:\", np.min(noiseAudio),\"Max:\",np.max(noiseAudio))\n","ipd.Audio(data=noiseAudio, rate=sr) # load a local WAV file"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:28:58.265507Z","iopub.status.busy":"2023-02-21T16:28:58.265057Z","iopub.status.idle":"2023-02-21T16:28:58.284578Z","shell.execute_reply":"2023-02-21T16:28:58.283675Z","shell.execute_reply.started":"2023-02-21T16:28:58.265470Z"},"id":"bu_eOKRfTHbp","trusted":true},"outputs":[],"source":["cleanAudioFeatureExtractor = FeatureExtractor(cleanAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n","stft_features = cleanAudioFeatureExtractor.get_stft_spectrogram()\n","stft_features = np.abs(stft_features)\n","print(\"Min:\", np.min(stft_features),\"Max:\",np.max(stft_features))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:29:01.610577Z","iopub.status.busy":"2023-02-21T16:29:01.610214Z","iopub.status.idle":"2023-02-21T16:29:01.625605Z","shell.execute_reply":"2023-02-21T16:29:01.624666Z","shell.execute_reply.started":"2023-02-21T16:29:01.610546Z"},"id":"sHWcmobyTP4E","trusted":true},"outputs":[],"source":["noisyAudio = add_noise_to_clean_audio(cleanAudio, noiseAudio)\n","ipd.Audio(data=noisyAudio, rate=fs) # load a local WAV file"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:29:14.490375Z","iopub.status.busy":"2023-02-21T16:29:14.490000Z","iopub.status.idle":"2023-02-21T16:29:14.499361Z","shell.execute_reply":"2023-02-21T16:29:14.498395Z","shell.execute_reply.started":"2023-02-21T16:29:14.490342Z"},"id":"75M29dl3bBeF","trusted":true},"outputs":[],"source":["def prepare_input_features(stft_features):\n","    # Phase Aware Scaling: To avoid extreme differences (more than\n","    # 45 degree) between the noisy and clean phase, the clean spectral magnitude was encoded as similar to [21]:\n","    noisySTFT = np.concatenate([stft_features[:,0:numSegments-1], stft_features], axis=1)\n","    stftSegments = np.zeros((numFeatures, numSegments , noisySTFT.shape[1] - numSegments + 1))\n","\n","    for index in range(noisySTFT.shape[1] - numSegments + 1):\n","        stftSegments[:,:,index] = noisySTFT[:,index:index + numSegments]\n","    return stftSegments"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:29:16.400382Z","iopub.status.busy":"2023-02-21T16:29:16.399627Z","iopub.status.idle":"2023-02-21T16:29:16.416391Z","shell.execute_reply":"2023-02-21T16:29:16.415012Z","shell.execute_reply.started":"2023-02-21T16:29:16.400340Z"},"id":"9cjO5-cjTP6t","trusted":true},"outputs":[],"source":["noiseAudioFeatureExtractor = FeatureExtractor(noisyAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n","noise_stft_features = noiseAudioFeatureExtractor.get_stft_spectrogram()\n","\n","# Paper: Besides, spectral phase was not used in the training phase.\n","# At reconstruction, noisy spectral phase was used instead to\n","# perform in- verse STFT and recover human speech.\n","noisyPhase = np.angle(noise_stft_features)\n","print(noisyPhase.shape)\n","noise_stft_features = np.abs(noise_stft_features)\n","\n","mean = np.mean(noise_stft_features)\n","std = np.std(noise_stft_features)\n","noise_stft_features = (noise_stft_features - mean) / std"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:29:18.131657Z","iopub.status.busy":"2023-02-21T16:29:18.131294Z","iopub.status.idle":"2023-02-21T16:29:18.142896Z","shell.execute_reply":"2023-02-21T16:29:18.141980Z","shell.execute_reply.started":"2023-02-21T16:29:18.131625Z"},"id":"3p5PWWkrlE3m","trusted":true},"outputs":[],"source":["predictors = prepare_input_features(noise_stft_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:29:19.531803Z","iopub.status.busy":"2023-02-21T16:29:19.531431Z","iopub.status.idle":"2023-02-21T16:29:19.541538Z","shell.execute_reply":"2023-02-21T16:29:19.540335Z","shell.execute_reply.started":"2023-02-21T16:29:19.531771Z"},"id":"4pSoOw2fTP9N","trusted":true},"outputs":[],"source":["predictors = np.reshape(predictors, (predictors.shape[0], predictors.shape[1], 1, predictors.shape[2]))\n","predictors = np.transpose(predictors, (3, 0, 1, 2)).astype(np.float32)\n","print('predictors.shape:', predictors.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:29:21.183460Z","iopub.status.busy":"2023-02-21T16:29:21.182767Z","iopub.status.idle":"2023-02-21T16:29:22.278590Z","shell.execute_reply":"2023-02-21T16:29:22.277429Z","shell.execute_reply.started":"2023-02-21T16:29:21.183423Z"},"id":"a5sNR4sSTP_1","trusted":true},"outputs":[],"source":["STFTFullyConvolutional = model.predict(predictors)\n","print(STFTFullyConvolutional.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:29:23.755438Z","iopub.status.busy":"2023-02-21T16:29:23.754704Z","iopub.status.idle":"2023-02-21T16:29:23.762358Z","shell.execute_reply":"2023-02-21T16:29:23.760965Z","shell.execute_reply.started":"2023-02-21T16:29:23.755399Z"},"id":"LzCga3PdUVwG","trusted":true},"outputs":[],"source":["def revert_features_to_audio(features, phase, cleanMean=None, cleanStd=None):\n","    # scale the outpus back to the original range\n","    if cleanMean and cleanStd:\n","        features = cleanStd * features + cleanMean\n","\n","    phase = np.transpose(phase, (1, 0))\n","    features = np.squeeze(features)\n","\n","    # features = librosa.db_to_power(features)\n","    features = features * np.exp(1j * phase)  # that fixes the abs() ope previously done\n","\n","    features = np.transpose(features, (1, 0))\n","    return noiseAudioFeatureExtractor.get_audio_from_stft_spectrogram(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:29:25.298591Z","iopub.status.busy":"2023-02-21T16:29:25.297887Z","iopub.status.idle":"2023-02-21T16:29:25.869366Z","shell.execute_reply":"2023-02-21T16:29:25.867729Z","shell.execute_reply.started":"2023-02-21T16:29:25.298552Z"},"id":"LWlUDtPzURlQ","trusted":true},"outputs":[],"source":["denoisedAudioFullyConvolutional = revert_features_to_audio(STFTFullyConvolutional, noisyPhase, mean, std)\n","print(\"Min:\", np.min(denoisedAudioFullyConvolutional),\"Max:\",np.max(denoisedAudioFullyConvolutional))\n","ipd.Audio(data=denoisedAudioFullyConvolutional, rate=fs) # load a local WAV file"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-02-21T11:27:33.096896Z","iopub.status.idle":"2023-02-21T11:27:33.101080Z","shell.execute_reply":"2023-02-21T11:27:33.100831Z","shell.execute_reply.started":"2023-02-21T11:27:33.100806Z"},"id":"VvEIBy7EHgeP","trusted":true},"outputs":[],"source":["# A numeric identifier of the sound class -- Types of noise\n","# 0 = air_conditioner\n","# 1 = car_horn\n","# 2 = children_playing\n","# 3 = dog_bark\n","# 4 = drilling\n","# 5 = engine_idling\n","# 6 = gun_shot\n","# 7 = jackhammer\n","# 8 = siren\n","# 9 = street_music"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-21T16:29:38.989176Z","iopub.status.busy":"2023-02-21T16:29:38.988388Z","iopub.status.idle":"2023-02-21T16:29:39.578445Z","shell.execute_reply":"2023-02-21T16:29:39.577427Z","shell.execute_reply.started":"2023-02-21T16:29:38.989131Z"},"id":"tv_7ZwWaUW0_","trusted":true},"outputs":[],"source":["f, (ax1, ax2, ax3) = plt.subplots(3, 1, sharey=True)\n","\n","ax1.plot(cleanAudio)\n","ax1.set_title(\"Clean Audio\")\n","\n","ax2.plot(noisyAudio)\n","ax2.set_title(\"Noisy Audio\")\n","\n","ax3.plot(denoisedAudioFullyConvolutional)\n","ax3.set_title(\"Denoised Audio\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"SpeechDenoiserCNN.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"vscode":{"interpreter":{"hash":"6efcd66f1305ec1c9d81218fa46d306a710274500761d6d9999173f93b9b1113"}}},"nbformat":4,"nbformat_minor":4}
